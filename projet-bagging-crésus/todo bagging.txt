

nous voulons un "pixel-based classification" des images pour classer les images selon les class [Land Cover Class : Built-up (urban, sealed, soil, …);Grassland/Herbaceous;  Broadleafed woody vegetation; Coniferous woody vegetation; Cropland; Water] en utilisant les regles de décision sur les propritétés calculer à partir des images indexés en utilisant aux besoin les bandes à nommer [bandes_names : "NIR"; "RED"; "NDVI"; "SW1"; "SW2",...].  A la fin, il faut avoir entrainer  et tester le modèle de fôret aléatoire sur des images selectionner dans un dictionnaire "construction_model" puis valider le modèle sur les données non selectionner pour entrainement et test dans le dictionnaire "validation_model" avec dans chaque cas en sortie des matrice de confusion graphique (à sauvegader dans "Visualsiation) et des calcul de précision avec K-fold CV si besoin et en résulats final des carte classififier avec les colorations ou délimiatation des pixel selon la classe prédite à mettre cote à cote avec la vrai classe (à sauvegader dans "Visualsiation). Enfin refaire la partie entrainement, test, validation, classification en applicant cette fois-ci l'algo bagging et en sortant une visualisation de la performance comparer des deux méthodes (à sauvegader dans "Visualsiation) interprétation.


proposes un script court autant que possible, efficace et optimiser pour :
- etape 0 : Récupérer les images dans le dossier input_data = "sentinels_data" et refaire les images et les indexés en nommant les bandes selon les bandes_names [bandes_names : "NIR"; "RED"; "NDVI"; "SW1"; "SW2",...] ensuite, etiquettés les images selon une classe [Land Cover Class : Built-up (urban, sealed, soil, …);Grassland/Herbaceous;  Broadleafed woody vegetation; Coniferous woody vegetation; Cropland; Water]. Les étapes suivantes seront faites sur les images étiquettées.


proposes un script court autant que possible, efficace et optimiser pour :
- etape 1 : Créer un dictionnaire "construction_model" constitué d'une image par paire dans le dictionnaire des pair d'images qui se chevauchent "image_pairs" et d'une image dans le dictionnaire des images sans paire "single_images" (s'il y a au moins deux images sans pairs) puis créer un dictionnaire "validation_model" pour les images (pair et single) non selection selectionnées dans "construction_model". pour chaque dictionnaire la clé est la première partie du nom des fichiers (exemple : T32UNC pour T32UNC_20190619T103031_R60m) et la valeur c'est le chemin pour aller chercher le fichier (il suffit de garder la clé et la valeur pour les slections faites dans les dictionnaires  "single_images" et image_pairs.



proposes un script court autant que possible, efficace et optimiser pour :
- etape 2 : Je ne sais pas s'il faut calculer les indices (NVDI,SW1, etc.) en dehors à part
mais cette étape consiste à récupérer les images du dict "construction_model" pour créer 
la/les base(e)s training/test et entrainer le modèle et donner en sortie : graphique matrix de confusion , précision avec K-fold CV si besoin et en résulats final des cartes classififier avec les colorations ou délimiatation des pixel selon la classe prédite à mettre cote à cote avec la vrai classe (à sauvegader dans "Visualsiation).



proposes un script court autant que possible, efficace et optimiser pour :
- etape 3 : récupérer les images du dict "validation_mode" pour validation du modèle et donner en sortie : graphique matrix de confusion , précision avec K-fold CV si besoin et en résulats final des cartes classififier avec les colorations ou délimiatation des pixel selon la classe prédite à mettre cote à cote avec la vrai classe (à sauvegader dans "Visualsiation).



proposes un script court autant que possible, efficace et optimiser pour :
- etape 4 : reprendre les étapes 2 et 4 mais en appliquant l'ago bagging et donner en sortie : graphique matrix de confusion , précision avec K-fold CV si besoin et en résulats final des cartes classififier avec les colorations ou délimiatation des pixel selon la classe prédite à mettre cote à cote avec la vrai classe (à sauvegader dans "Visualsiation).


proposes un script court autant que possible, efficace et optimiser pour :
- etape 5 : produire sur graphique analyse comparative des performance de la foret aléaoire et de la foret aléatoire + bagging avec résulats finale carte classifier cote à cote pour l'étape validation avec afficher les précision (à sauvegader dans "Visualsiation).

interprétation de etape 5.

proposes des script court, efficace et optimaux pour réaliser etapes pas etapes ce qui est voulu. Si tu n'as pas assez de place pour tout écrire, recommencer à la fin après interruption.
 
